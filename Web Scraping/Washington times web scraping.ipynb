{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Washington Times News Scraper\n",
    "### You need Google Chrome for running this notebook\n",
    "\n",
    "#### When you already have Chrome installed:\n",
    "1. Go to the website: https://sites.google.com/chromium.org/driver/downloads?authuser=0\n",
    "2. Download a chrome driver that is the same version as your chrome\n",
    "3. Double click the driver to open it\n",
    "4. Come back here, start running the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.theamericanconservative.com/web-categories/politics/\"\n",
    "# the dictionary for storing links of news\n",
    "# dictionary can prevent duplicates\n",
    "article_links = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary libraries\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver   \n",
    "from requests import get\n",
    "import time\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import datetime\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import random\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This snippet will open a Washington Times page on Chrome\n",
    "# DON'T CLOSE THE WINDOW!\n",
    "driver = webdriver.Chrome('/Users/wufangzheng/Downloads/chromedriver') #set the webdriver to Chrome driver\n",
    "driver.get(url)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web-scrape links of news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "20 0\n",
      "40 0\n",
      "60 0\n",
      "80 0\n",
      "100 0\n",
      "120 0\n",
      "140 0\n",
      "160 0\n",
      "180 0\n",
      "200 0\n",
      "220 0\n",
      "240 0\n",
      "260 0\n",
      "280 0\n",
      "300 0\n",
      "320 0\n",
      "340 0\n",
      "360 0\n",
      "380 0\n",
      "400 0\n",
      "420 0\n",
      "440 0\n",
      "460 0\n",
      "480 0\n",
      "500 0\n",
      "520 25\n",
      "540 100\n",
      "560 100\n",
      "580 100\n",
      "600 100\n",
      "620 100\n",
      "640 100\n",
      "660 84\n",
      "Not auto loading\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-2ccbfc613239>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mhtml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mlinks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlisting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_elements_by_class_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"alm-item\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# The page can be infinitely scrolled down.\n",
    "# Keep scrolling the page and store LINKS of the politics news in article_links\n",
    "\n",
    "# This cell can fail every once in a while. Just re-run the cell when it fails.\n",
    "listing = driver.find_element_by_class_name(\"alm-listing\")\n",
    "last_length = 0\n",
    "for i in range(10000):\n",
    "    html = driver.find_element_by_tag_name('html')\n",
    "    html.send_keys(Keys.END)\n",
    "    \n",
    "    time.sleep(2)\n",
    "    if i%20==0:\n",
    "        links = listing.find_elements_by_class_name(\"alm-item\")\n",
    "        if len(links)== last_length:\n",
    "            html.send_keys(Keys.PAGE_UP)\n",
    "            html.send_keys(Keys.PAGE_DOWN)\n",
    "            \n",
    "            print(\"Not auto loading\")\n",
    "            continue\n",
    "        else:\n",
    "            last_length = len(links)\n",
    "        count = 0\n",
    "        for item in links:\n",
    "            link = item.find_element_by_tag_name(\"a\").get_attribute(\"href\")\n",
    "            if link not in article_links:\n",
    "                article_links[link] = 0\n",
    "                count+=1\n",
    "        print(str(i) + \" \" + str(count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web-scrape article text from those links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = list(article_links.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.theamericanconservative.com/articles/lessons-from-ukraine/\n",
      "This article has no content\n",
      "https://www.theamericanconservative.com/articles/local-and-global/\n",
      "This article has no content\n",
      "https://www.theamericanconservative.com/articles/the-peace-coalition/\n",
      "This article has no content\n",
      "https://www.theamericanconservative.com/articles/capitalisms-balance/\n",
      "This article has no content\n",
      "https://www.theamericanconservative.com/articles/from-pushkin-to-putin/\n",
      "This article has no content\n",
      "https://www.theamericanconservative.com/articles/big-government-little-tea-party/\n",
      "This article has no content\n",
      "https://www.theamericanconservative.com/articles/libertarianisms-limits/\n",
      "This article has no content\n",
      "https://www.theamericanconservative.com/articles/iran-is-ready-for-a-deal/\n",
      "This article has no content\n",
      "3000\n",
      "Time Spent: 345.0810749530792\n",
      "3200\n",
      "Time Spent: 482.9792912006378\n"
     ]
    }
   ],
   "source": [
    "# Open every link from the links, and web-scrape text from it, and store the data to FOX_articles.csv\n",
    "\n",
    "# The data we scrape: title, text (article body), date\n",
    "# The output data will have the format of: index, date, title, text, label(left/lean left/neutral/lean right/right), link\n",
    "\n",
    "# Note that I have to use selenium to scrape content as this website prevents from Beautiful Soup scraping.\n",
    "\n",
    "# This cell may also fail\n",
    "# Every time it fails, just re-run this cell. It will automatically continue with the remaining links\n",
    "\n",
    "driver = webdriver.Chrome('/Users/wufangzheng/Downloads/chromedriver') #set the webdriver to Chrome driver\n",
    "current_time = time.time()\n",
    "difference = real_count - count\n",
    "start_point = real_count\n",
    "count = start_point-difference - 1\n",
    "for link in links[start_point:]:\n",
    "    real_count +=1\n",
    "    count+=1\n",
    "#     if count>3:\n",
    "#         break\n",
    "\n",
    "    # Open the link in a Chrome window\n",
    "    driver.get(link)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    # Find content of the article\n",
    "    try:\n",
    "        article = driver.find_element_by_class_name(\"c-single-blog__content\")\n",
    "    except NoSuchElementException:\n",
    "        print(link)\n",
    "        print(\"This article has no content\")\n",
    "        count-=1\n",
    "        continue\n",
    "\n",
    "    if not article:\n",
    "        count-=1\n",
    "        print(\"This link does not contain article:\")\n",
    "        print(link)\n",
    "        continue\n",
    "        \n",
    "    # Find paragraphes\n",
    "    paras = article.find_elements_by_tag_name(\"p\")\n",
    "    text = \"\"\n",
    "    for item in paras:\n",
    "        text+=item.text+\"\\n\"\n",
    "#     print(text)\n",
    "\n",
    "    # Find title\n",
    "    title = driver.find_element_by_class_name(\"c-single-blog__title\")\n",
    "    \n",
    "    title = title.text\n",
    "        \n",
    "    # Find date\n",
    "    date = driver.find_element_by_class_name(\"c-post-meta__date\").text\n",
    "    date = convertdate(date)\n",
    "    if date==\"error\":\n",
    "        count-=1\n",
    "        print(\"error date!\")\n",
    "        print(link)\n",
    "        continue\n",
    "#     date = soup.find('div', class_ = \"article-body__date-source\")\n",
    "#     if not date:\n",
    "#         date = soup.find('div', class_=\"article-hero-headline__timestamp\")\n",
    "#     date = date.find('time')['datetime']\n",
    "#     date = convertdate(date)\n",
    "#     if date == \"error\":\n",
    "#         print(\"date is not scraped\")\n",
    "#         print(link)\n",
    "#         count-=1\n",
    "#         continue\n",
    "\n",
    "    # Store data\n",
    "    with open(\"Washington_times_articles.csv\", \"a\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow([str(count),\n",
    "                         date,\n",
    "                         title,\n",
    "                         text,\n",
    "                         \"lean right\",\n",
    "                         link])\n",
    "    if count%200 == 0:\n",
    "        print(count)\n",
    "        print(\"Time Spent: \" + str(time.time()-current_time))\n",
    "        current_time = time.time()\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3288\n",
      "3299\n",
      "https://www.theamericanconservative.com/articles/whose-war/\n"
     ]
    }
   ],
   "source": [
    "print(count)\n",
    "print(real_count)\n",
    "print(links[real_count-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function used when scraping date from websites\n",
    "def convertdate(datestr):\n",
    "    datestr = datestr.split(\", \")\n",
    "    year = datestr[1]\n",
    "    month = datestr[0].split(\" \")[0]\n",
    "    day = datestr[0].split(\" \")[1]\n",
    "    if month == \"January\".upper():\n",
    "        month = \"01\"\n",
    "    elif month == \"February\".upper():\n",
    "        month = \"02\"\n",
    "    elif month == \"March\".upper():\n",
    "        month = \"03\"\n",
    "    elif month == \"April\".upper():\n",
    "        month = \"04\"\n",
    "    elif month == \"May\".upper():\n",
    "        month = \"05\"\n",
    "    elif month == \"June\".upper():\n",
    "        month = \"06\"\n",
    "    elif month == \"July\".upper():\n",
    "        month = \"07\"\n",
    "    elif month == \"August\".upper():\n",
    "        month = \"08\"\n",
    "    elif month == \"September\".upper():\n",
    "        month = \"09\"\n",
    "    elif month == \"October\".upper():\n",
    "        month = \"10\"\n",
    "    elif month == \"November\".upper():\n",
    "        month = \"11\"\n",
    "    elif month == \"December\".upper():\n",
    "        month = \"12\"\n",
    "    else:\n",
    "        print(\"Error!\")\n",
    "        return \"error\"\n",
    "    return year+\"/\"+month+\"/\"+day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "real_count = 0\n",
    "for link in article"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
