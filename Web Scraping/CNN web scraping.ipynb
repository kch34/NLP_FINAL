{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN News Scraper\n",
    "### You need Google Chrome for running this notebook\n",
    "\n",
    "#### When you already have Chrome installed:\n",
    "1. Go to the website: https://sites.google.com/chromium.org/driver/downloads?authuser=0\n",
    "2. Download a chrome driver that is the same version as your chrome\n",
    "3. Double click the driver to open it\n",
    "4. Come back here, start running the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary libraries\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver   \n",
    "from requests import get\n",
    "import time\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This snippet will open a chrome window, search on CNN for politics articles, and display 30 results\n",
    "# DON'T CLOSE THE WINDOW!\n",
    "\n",
    "url = \"https://www.cnn.com/search?q=Republicans&size=30&page=1&from=0&category=politics&type=article\"\n",
    "driver = webdriver.Chrome('/Users/wufangzheng/Downloads/chromedriver') #set the webdriver to Chrome driver\n",
    "driver.get(url)                                                        #now we can use selenium to access this website\n",
    "# # time.sleep(3)                                                        \n",
    "# nextButton = driver.find_element_by_class_name(\"pagination-arrow-right\")\n",
    "# nextButton.click()\n",
    "# # time.sleep(3)\n",
    "# resultList = driver.find_elements_by_class_name(\"cnn-search__result-thumbnail\")\n",
    "articleLinks = {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web-scrape links of news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After the window is successfully opened, run this cell\n",
    "# This cell of code will get URLs of the displayed 30 articles and put them into a dictionary, then jump to next page\n",
    "\n",
    "# The URL of politics articles always starts with \"https://www.cnn.com/xxxx/xx/xx/politics/\", \n",
    "# those URLs without this pattern will not be added to the dictionary\n",
    "\n",
    "# The dictionary removes duplicates\n",
    "\n",
    "# It may fail every once in a while, everytime it fails, just re-run this cell.\n",
    "\n",
    "# You will keep having more article links stored into the dictionary\n",
    "# as long as you don't close the chrome window\n",
    "for i in range(334):\n",
    "    resultList = driver.find_elements_by_class_name(\"cnn-search__result-thumbnail\")\n",
    "    for article in resultList:\n",
    "        link = article.find_element_by_tag_name('a').get_attribute('href')\n",
    "        x = re.search('^https://www.cnn.com/\\d{4}/\\d{2}/\\d{2}/politics/', link)\n",
    "        if (x==None):\n",
    "#             print(\"This is not a politics article\")\n",
    "#             print(link)\n",
    "            continue\n",
    "        else:\n",
    "            if int(re.search('\\d{4}/\\d{2}/\\d{2}', link)[0].split(\"/\")[0]) <2010:\n",
    "                print(\"This article is outdated\")\n",
    "                print(link)\n",
    "                continue\n",
    "        if link in articleLinks:\n",
    "#             print(\"this link exists\")\n",
    "#             print(link)\n",
    "            continue\n",
    "        articleLinks[link] = 0\n",
    "    nextButton = driver.find_element_by_class_name(\"pagination-arrow-right\")\n",
    "    nextButton.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63491"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many links it has scraped\n",
    "len(articleLinks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save article links as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(articleLinks)\n",
    "# len(df)\n",
    "s = pd.Series(articleLinks.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.to_pickle(\"./63491_article_links_cnn.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.read_pickle(\"./63491_article_links_cnn.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.cnn.com/2017/10/05/politics/heart-of-texas-russia-event/index.html\n"
     ]
    }
   ],
   "source": [
    "print(s[30000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With article links, web-scrape title, content, time,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open every link from the articleLinks, and web-scrape text from it, and store the data to CNN_articles.csv\n",
    "\n",
    "# The data we scrape: title, text (article body), date\n",
    "# The output data will have the format of: index, date, title, text, label(left/lean left/neutral/lean right/right), link\n",
    "\n",
    "\n",
    "# This cell may also fail\n",
    "# Every time it fails, check the number stored in variable \"count\", and change the variable \"startpoint\" to that number\n",
    "# E.g.: print(str(count)) outputs 355\n",
    "#       then do: startpoint = 355\n",
    "#       and re-run this snippet\n",
    "startpoint = 0\n",
    "count = 0\n",
    "for link in s:\n",
    "    count+=1\n",
    "    if count<=startpoint:\n",
    "        continue\n",
    "    while True:\n",
    "        page = get(link)\n",
    "        if page.status_code == 200:\n",
    "            break\n",
    "        else:\n",
    "            print(\"Access denied! Reconnect in 5 seconds...\")\n",
    "            time.sleep(5)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    paragraphs = soup.find_all('div', class_='zn-body__paragraph')\n",
    "    title = soup.title.text\n",
    "    brief = soup.find('p', class_='zn-body__paragraph')\n",
    "\n",
    "    text = \"\"\n",
    "    if len(paragraphs)!=0:\n",
    "        if brief!=None:\n",
    "            text+=brief.text+'\\n'\n",
    "        for para in paragraphs:\n",
    "            text+=para.text+'\\n'\n",
    "    else:\n",
    "        paragraphs = soup.find_all('p', class_=\"paragraph\")\n",
    "        for para in paragraphs:\n",
    "            text+=para.text\n",
    "\n",
    "    date = re.search('\\d{4}/\\d{2}/\\d{2}', link)\n",
    "    if not date:\n",
    "        print(\"This article does not have date, skip\")\n",
    "        continue\n",
    "        \n",
    "    # write the scraped data in the following format\n",
    "    with open('CNN_articles.csv', 'a') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile)\n",
    "        csvwriter.writerow([str(count), date[0], title, text, \"left\", link])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fact check: Biden makes misleading claim about job-creation estimate  - CNNPolitics\n",
      "2021/10/09\n",
      "https://www.cnn.com/2021/10/08/politics/us-taliban-doha-meetings/index.html\n",
      "Washington (CNN)In a speech in Michigan on Tuesday and again in a speech back in Washington on Friday, President Joe Biden touted the potential economic impact of his two major current legislative proposals: a $1 trillion bipartisan infrastructure bill and a larger, still-being-negotiated Democratic reconciliation package that would expand the social safety net in various ways.\n",
      "Biden said in Michigan that, earlier this year, \"a Wall Street outfit called Moody's projected that the investments in these bills could help our economy create an additional 2 million jobs per year, every year. Two million per year. That's going to bte transformative.\"\n",
      "On Friday, Biden omitted the word \"help.\" This time, he said that Moody's Analytics projected that the bills would produce \"an additional 2 million jobs per year.\"\n",
      "Facts First: Biden's remarks were misleading -- because he created the impression that Moody's Analytics projected a much bigger jobs impact from his two new bills than Moody's actually did. Contrary to Biden's suggestion, Moody's did not find that the passage of the two bills would produce an additional 2 million jobs in each successive year. In other words, Moody's did not find that in 10 years, the economy would have 20 million extra jobs because of Biden's bills. Rather, Moody's found that in 10 years, the economy would have 2.2 million more jobs if the bipartisan infrastructure bill and a $3.5 trillion spending package were passed than it would if they were not passed. \n",
      "A White House official explained to CNN that Biden was referring not to an additive figure but to an average figure -- the fact that Moody's found that, between 2022 and 2031, the average level of nonfarm employment would be nearly 2 million jobs higher if the bills were passed than it would be otherwise. Presented with this White House explanation, Moody's Analytics chief economist Mark Zandi, said it was a valid way to assess the impact of economic legislation. \n",
      "But Zandi still took issue with Biden's own comments -- saying they were likely to leave Americans with an inaccurate impression of what Moody's found. In fact, until he was sent the White House explanation, Zandi -- who co-authored the July report Biden was citing -- himself did not understand Biden's assertions about the report's findings.\n",
      "Zandi said of Biden's words: \"I would say they were incomplete. Or not well explained.\"\n",
      "This is the second Moody's report this year that Biden has described misleadingly.\n",
      "What Moody's found\n",
      "Here's the problem with Biden's description of the Moody's data from July. \n",
      "When Biden says that Moody's found his bills would create \"an additional 2 million jobs per year,\" and especially when he emphasizes the \"every year\" as he did in Michigan, he makes it sound like Moody's found that the passage of the bills would result in 10 million more jobs after five years than would exist if the bills didn't pass, or 20 million more jobs after 10 years than would exist if the bills didn't pass. \n",
      "But that's not what Moody's found.\n",
      "Moody's found that, five years down the road in 2026, passage of the bipartisan infrastructure bill and a $3.5 trillion reconciliation package would mean that 2.5 million Americans would have jobs who otherwise wouldn't (157.2 million jobs with the two new bills and the American Rescue Plan that Biden signed into law in March versus 154.7 million jobs with the American Rescue Plan alone). And Moody's found that, 10 years down the road in 2031, passage of the two new bills would mean that 2.2 million Americans would have jobs who otherwise wouldn't (161.4 million jobs with the bills versus 159.2 million jobs with the American Rescue Plan alone).  \n",
      "To look at the Moody's report a different way: Moody's found that the economy would add 12 million jobs between the first quarter of 2022 and the last quarter of 2031 if the two new bills were passed, or add 9.9 million jobs if the two bills weren't passed. That's a gain of 2.1 million jobs over this period.\n",
      "So what was Biden talking about when he spoke of Moody's projecting an additional 2 million jobs \"per year, every year\"?\n",
      "The annual average, the White House said.\n",
      "The White House official noted that Moody's found that, on average, in the years from 2022 through 2031, there would be nearly 2 million extra people employed with the passage of the bipartisan infrastructure bill and a $3.5 trillion reconciliation package than if these bills did not pass.\n",
      "The White House math\n",
      "Here's how the White House calculated the average.\n",
      "Moody's found that in 2022, there would be 150.8 million people employed if the two bills were passed or 150.5 million people employed if the bills were not passed. That's a difference of 300,000 jobs.\n",
      "Then, in 2023, there would be 153 million people employed if the two bills were passed versus 152.1 million people employed if they were not passed. That's a difference of 900,000 jobs.\n",
      "In 2024, the difference would be 1.5 million. In 2025, it would be 2.2 million. In 2026, it would be 2.5 million. In 2027, it would rise to its highest point, 2.6 million. Then it would be 2.4 million in 2028, 2.3 million in 2029 and again in 2030, and 2.2 million in 2031.\n",
      "If you take the average of these annual differences from 2022 to 2031, you get 1.9 million. That's close to the \"2 million\" number Biden used.\n",
      "Still, Biden did not explain that the \"2 million\" figure was the product of this kind of calculation. \n",
      "Final analysis\n",
      "If the President wants to communicate that, on average over the next decade, Moody's found there would be about 2 million more people employed if his bills are passed than if his bills aren't passed, he can say that explicitly. \n",
      "There's one other key point here. As noted above, these Moody's estimates are based on the initial $3.5 trillion Democratic proposal for the reconciliation package. But it has been clear for weeks that the final reconciliation package will have to be made much smaller than $3.5 trillion -- possibly less than half that size -- to earn the necessary votes of two holdout Senate Democrats, Kyrsten Sinema of Arizona and Joe Manchin of West Virginia.\n",
      "Zandi told CNN that a bill smaller than $3.5 trillion would have a smaller jobs impact than the one projected in the Moody's report.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print out content of the last article\n",
    "print(title)\n",
    "print(date[0])\n",
    "print(link)\n",
    "print(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
